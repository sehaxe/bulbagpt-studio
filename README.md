# ü•î BulbaGPT Studio: Scientific AI Foundry

![Version](https://img.shields.io/badge/version-2.5-blue) ![Rust](https://img.shields.io/badge/Core-Rust-orange) ![PyTorch](https://img.shields.io/badge/PyTorch-BFloat16-red) ![Gradio](https://img.shields.io/badge/UI-Gradio-orange)

**BulbaGPT Studio** ‚Äî —ç—Ç–æ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ä–µ–¥–∞ (IDE) –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Å–æ–∑–¥–∞–Ω–∏—è –º–∞–ª—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (SLM) —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π **Custom Llama-3 (GQA)**.

–ú—ã –∑–∞–º–µ–Ω–∏–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω HuggingFace (Dataset/DataLoader) –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ —è–¥—Ä–æ **Rust Core**, —Ä–∞–±–æ—Ç–∞—é—â–µ–µ —á–µ—Ä–µ–∑ FFI. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–æ–º –∂–µ–ª–µ–∑–µ (8-24GB VRAM) —Å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é –¥–∞—Ç–∞-—Ü–µ–Ω—Ç—Ä–æ–≤, —É—Å—Ç—Ä–∞–Ω—è—è `Memory Wall` –∏ `GIL Locking`.

> *"–ö–æ–º–±–∞–π–Ω, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –≤ GGUF-–º–æ–¥–µ–ª—å, –≥–æ—Ç–æ–≤—É—é –∫ —á–∞—Ç—É, –≤—ã–∂–∏–º–∞—è 100% –∏–∑ –≤–∞—à–µ–≥–æ –∂–µ–ª–µ–∑–∞."*

---

## üß¨ –ö–ª—é—á–µ–≤—ã–µ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ v2.5

### 1. Rust Data Engine (Zero-Copy)
–í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ –≤—ã–Ω–µ—Å–µ–Ω—ã –∏–∑ Python –≤ –Ω–∞—Ç–∏–≤–Ω—ã–π –∫–æ–¥:
*   **In-Memory Tokenizer Trainer:** Rust —Å–∞–º –æ–±—É—á–∞–µ—Ç BPE-—Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –Ω–∞ –ª–µ—Ç—É, —Å–æ–∑–¥–∞–≤–∞—è —Å–ª–æ–≤–∞—Ä—å, –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥–æ–≥–Ω–∞–Ω–Ω—ã–π –ø–æ–¥ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ (–Ω–µ—Ç "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤").
*   **Smart Bucketing Loader:** –î–∞–Ω–Ω—ã–µ —á–∏—Ç–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ `mmap` –∏ –≥—Ä—É–ø–ø–∏—Ä—É—é—Ç—Å—è –ø–æ –¥–ª–∏–Ω–µ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏. –≠—Ç–æ —É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ 15-20% –∏ —Å–Ω–∏–∂–∞–µ—Ç –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ –¥–∏—Å–∫ (Sequential Read).
*   **Parallel Processor:** –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –≥–∏–≥–∞–±–∞–π—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞ –∑–∞ —Å–µ–∫—É–Ω–¥—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Å–µ—Ö —è–¥–µ—Ä CPU (`Rayon`).

### 2. Modern Training Architecture
*   **BFloat16 Native:** –û–±—É—á–µ–Ω–∏–µ –≤ "—á–∏—Å—Ç–æ–º" `bf16` (–¥–ª—è RTX 30xx/40xx –∏ Mac M-series), —á—Ç–æ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ Mixed Precision.
*   **NEFTune (Noisy Embeddings):** –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –º–∞–ª—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö.
*   **8-bit Optimizers:** –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è `bitsandbytes` –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ VRAM (–ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏ 600M+ –Ω–∞ –∫–∞—Ä—Ç–∞—Ö —Å 8GB).

### 3. Native GGUF Pipeline
–ë–æ–ª—å—à–µ –Ω–∏–∫–∞–∫–∏—Ö `NotImplementedError` –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –°—Ç—É–¥–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–∞—Ç—á–∏—Ç —Å–∫—Ä–∏–ø—Ç—ã `llama.cpp` –∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º –∫–æ–Ω—Ñ–∏–≥–æ–º Llama-3.

---

## üìê –ü—Ä–µ—Å–µ—Ç—ã –ú–æ–¥–µ–ª–µ–π

–°—Ç—É–¥–∏—è –≤–∫–ª—é—á–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, –±–∞–ª–∞–Ω—Å–∏—Ä—É—é—â–∏–µ –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º —É–º–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç—å—é –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (GQA Ratio):

| –ú–æ–¥–µ–ª—å | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã | VRAM (Train) | –û–ø–∏—Å–∞–Ω–∏–µ |
| :--- | :--- | :--- | :--- |
| **üê∞ Krolik** | **45M** | < 4 GB | –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –ø–∞–π–ø–ª–∞–π–Ω–∞. |
| **üê¶ Vorona** | **110M** | ~6 GB | –ê–Ω–∞–ª–æ–≥ TinyLlama, –±–∞–∑–æ–≤—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç. |
| **ü¶¢ AIst** | **250M** | ~8 GB | **–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ.** –ë–∞–ª–∞–Ω—Å —Å–ª–æ–µ–≤ (16) –∏ –≥–æ–ª–æ–≤ (16). –û—Ç–ª–∏—á–Ω—ã–π SLM –¥–ª—è RAG. |
| **ü¶¨ Zubr** | **600M** | ~10-12 GB | –ú–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å. –¢—Ä–µ–±—É–µ—Ç 8-bit AdamW –Ω–∞ –∫–∞—Ä—Ç–∞—Ö 8GB. |

---

## üõ† –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
*   **Python 3.10+**
*   **Rust Toolchain** (–¥–ª—è —Å–±–æ—Ä–∫–∏ —è–¥—Ä–∞)

### 1. Linux / WSL2 (NVIDIA)
*–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (Flash Attention 2, Compile).*

```bash
# 1. –°–æ–∑–¥–∞–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ
conda create -n bulba python=3.11
conda activate bulba

# 2. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Rust (–µ—Å–ª–∏ –Ω–µ—Ç)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env

# 3. –°–æ–±–∏—Ä–∞–µ–º Rust-—è–¥—Ä–æ (–ö–†–ò–¢–ò–ß–ù–û!)
pip install maturin
cd bulba_rust
maturin develop --release
cd ..

# 4. –°—Ç–∞–≤–∏–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt
# (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) Flash Attention 2
pip install flash-attn --no-build-isolation
```

### 2. macOS (Apple Silicon)
*–ù–∞—Ç–∏–≤–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Metal (MPS). –†–∞–±–æ—Ç–∞–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ.*

```bash
# 1. –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
brew install rust

# 2. –û–∫—Ä—É–∂–µ–Ω–∏–µ
conda create -n bulba python=3.11
conda activate bulba

# 3. –°–±–æ—Ä–∫–∞ —è–¥—Ä–∞
cd bulba_rust
maturin develop --release
cd ..

# 4. PyTorch Nightly (–¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–≥–æ–≤ MPS)
pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu
pip install -r requirements.txt
```

---

## üöÄ Workflow

### –®–∞–≥ 1: –ú–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
–°–∫—Ä–∏–ø—Ç `dataset.py` ‚Äî —ç—Ç–æ "DJ", –∫–æ—Ç–æ—Ä—ã–π —Å–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (–ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã, HuggingFace, JSONL) –∏ —Å–º–µ—à–∏–≤–∞–µ—Ç –∏—Ö –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏, —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É—è –ø–æ–¥ Llama-3 Instruct.

```bash
python dataset.py
# –†–µ–∑—É–ª—å—Ç–∞—Ç: data/aist_mixed.txt
```

### –®–∞–≥ 2: –û–±—É—á–µ–Ω–∏–µ (Web UI)
–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å—Ç—É–¥–∏—é:
```bash
python main.py
```
–û—Ç–∫—Ä–æ–π—Ç–µ `http://127.0.0.1:7860`:

1.  **–í–∫–ª–∞–¥–∫–∞ Train:**
    *   –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã (–∏–ª–∏ –æ—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç—ã–º, –æ–Ω –Ω–∞–π–¥–µ—Ç `aist_mixed.txt` —Å–∞–º).
    *   –ù–∞–∂–º–∏—Ç–µ **"1. Prepare Data & Tokenizer"**. Rust –æ–±—É—á–∏—Ç BPE, —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –ø–µ—Ä–µ–º–µ—à–∞–µ—Ç –µ–≥–æ.
    *   –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ—Å–µ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, **AIst 250M**) –∏ –≤–∫–ª—é—á–∏—Ç–µ **"Use NEFTune"**.
    *   –ù–∞–∂–º–∏—Ç–µ **"2. START"**.

2.  **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:**
    *   –°–ª–µ–¥–∏—Ç–µ –∑–∞ –≥—Ä–∞—Ñ–∏–∫–æ–º Loss –ø—Ä—è–º–æ –≤ UI.
    *   –í —Ç–µ—Ä–º–∏–Ω–∞–ª–µ –±—É–¥–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å—Å—è —Å–∫–æ—Ä–æ—Å—Ç—å (tokens/sec) –∏ ETA.
    *   –ó–∞–ø—É—â–µ–Ω —Ñ–æ–Ω–æ–≤—ã–π TensorBoard (`localhost:6006`).

### –®–∞–≥ 3: –≠–∫—Å–ø–æ—Ä—Ç
–ö–æ–≥–¥–∞ Loss —É–ø–∞–¥–µ—Ç –¥–æ –ø—Ä–∏–µ–º–ª–µ–º–æ–≥–æ —É—Ä–æ–≤–Ω—è (–æ–±—ã—á–Ω–æ < 3.0 –¥–ª—è SLM):
1.  –û—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ –∏–ª–∏ –¥–æ–∂–¥–∏—Ç–µ—Å—å –∫–æ–Ω—Ü–∞.
2.  –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤–æ –≤–∫–ª–∞–¥–∫—É **Export**.
3.  –í—ã–±–µ—Ä–∏—Ç–µ —á–µ–∫–ø–æ–∏–Ω—Ç –∏ –Ω–∞–∂–º–∏—Ç–µ **"Convert GGUF"**.
4.  –ó–∞–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª `.gguf` –∏–∑ –ø–∞–ø–∫–∏ `output_models`.

---

## üß† –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

*   `bulba_rust/` ‚Äî –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ —è–¥—Ä–∞ (Rust).
    *   `lib.rs` ‚Äî Python-–±–∏–Ω–¥–∏–Ω–≥–∏.
    *   `trainer.rs` ‚Äî –û–±—É—á–µ–Ω–∏–µ BPE —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞.
    *   `loader.rs` ‚Äî Smart Mmap DataLoader.
    *   `processor.rs` ‚Äî –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è.
*   `main.py` ‚Äî –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∏ —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è (PyTorch).
*   `dataset.py` ‚Äî –õ–æ–≥–∏–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ—Ä–ø—É—Å–∞.

---

License: MIT  
**BulbaGPT Project** üáßüáæ ‚Äî Science meets Engineering.